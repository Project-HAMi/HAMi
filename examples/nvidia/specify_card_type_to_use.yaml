apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
  annotations:
<<<<<<< HEAD
    # You can run command: kubectl get node $node -o jsonpath='{.metadata.annotations.hami\.io/node-nvidia-register}' to get registered gpu info
    # The full GPU type name is like NVIDIA-NVIDIA A100, while the short name is like A100
    nvidia.com/use-gputype: "A100,V100" # Specify the card type for this job, use comma to separate, will launch job on specified card
    # In this example, we want to run this job on A100 or V100
=======
    nvidia.com/use-gputype: "A100,V100" # Specify the card type for this job, use comma to seperate, will not launch job on non-specified card
    #In this example, we want to run this job on A100 or V100
>>>>>>> 21785f7 (update to v2.3.2)
spec:
  containers:
    - name: ubuntu-container
      image: ubuntu:18.04
      command: ["bash", "-c", "sleep 86400"]
      resources:
        limits:
<<<<<<< HEAD
          nvidia.com/gpu: 2 # declare how many physical GPUs the pod needs
=======
          nvidia.com/gpu: 2 # requesting 2 vGPUs
>>>>>>> 21785f7 (update to v2.3.2)
