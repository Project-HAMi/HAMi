apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
  annotations:
<<<<<<< HEAD
    # You can run command: kubectl get node $node -o jsonpath='{.metadata.annotations.hami\.io/node-nvidia-register}' to get registered gpu info
    # The full GPU type name is like NVIDIA-NVIDIA A100, while the short name is like A100
    nvidia.com/nouse-gputype: "1080,2080" # Specify the blacklist card type for this job, use comma to separate, will not launch job on specified card
    # In this example, we don't want our job to run on 1080(include 1080Ti) or 2080(include 2080Ti) type of card.
=======
    nvidia.com/nouse-gputype: "1080,2080" # Specify the blacklist card type for this job, use comma to seperate, will not launch job on specified card
    # In this job, we don't want our job to run on 1080(include 1080Ti) or 2080(include 2080Ti) type of card.
>>>>>>> 21785f7 (update to v2.3.2)
spec:
  containers:
    - name: ubuntu-container
      image: ubuntu:18.04
      command: ["bash", "-c", "sleep 86400"]
      resources:
        limits:
<<<<<<< HEAD
          nvidia.com/gpu: 2 # declare how many physical GPUs the pod needs
=======
          nvidia.com/gpu: 2 # requesting 2 vGPUs
>>>>>>> 21785f7 (update to v2.3.2)
